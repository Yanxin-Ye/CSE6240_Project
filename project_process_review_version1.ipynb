{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyTYRP3y0HFE"
   },
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# # print(os.path.abspath(\"steam_reviews.json\"))\n",
    "# print(os.getcwd())\n",
    "# os.chdir('/content/gdrive/My Drive/Colab Notebooks/') \n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8m1FGUuw17Z"
   },
   "outputs": [],
   "source": [
    "## To increase RAM size\n",
    "# a = []\n",
    "# while(1):\n",
    "#     a.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yanxi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# print (stopwords.words(\"english\"))\n",
    "from copy import deepcopy\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=open('australian_user_reviews.json','r', encoding=\"utf-8\")\n",
    "# cnt=1\n",
    "\n",
    "# for line in f.readlines():\n",
    "#     line=line[2:(len(line)-5)]\n",
    "#     line=line.split('\\', \\'')\n",
    "#     # print(line)\n",
    "#     for word in line:\n",
    "#         pair=word.split('\\': \\'')\n",
    "#         print(pair)\n",
    "#         # word=pair\n",
    "\n",
    "#     # df=pd.DataFrame(data=d)\n",
    "#     # data=pd.concat([data, df],axis=0,ignore_index=True,sorted=False)\n",
    "\n",
    "#     print(line)\n",
    "\n",
    "#     cnt=cnt+1\n",
    "#     if cnt==2:\n",
    "#         break\n",
    "#         # print(cnt)\n",
    "\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open('australian_user_reviews.json',encoding=\"utf-8\") as json_file:\n",
    "#     data = json.load(json_file)\n",
    "#     # for p in data['people']:\n",
    "#     #     print('Name: ' + p['name'])\n",
    "#     #     print('Website: ' + p['website'])\n",
    "#     #     print('From: ' + p['from'])\n",
    "#     #     print('')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "alldata = pd.read_csv(\"steam_reviews_kaggle.csv\")\n",
    "SentimentData=['review','recommendation']\n",
    "data=alldata[SentimentData]\n",
    "# data=data[pd.isna(data.review)==False]\n",
    "# data.drop(data.index[pd.isna(data.review)==False])\n",
    "data=data.dropna(subset=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n",
    "# data.review.isnull().sum()\n",
    "# print(len(alldata))\n",
    "# print(len(data))\n",
    "# alldata.title.describe()\n",
    "# alldata.recommendation.describe()\n",
    "# data[433370:433376]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yanxi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def clean_review(review, remove_stopwords = False):\n",
    "\n",
    "    review_text = BeautifulSoup(review,\"lxml\").get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    cleaned_review = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        cleaned_review = [w for w in cleaned_review if not w in stops]\n",
    "    \n",
    "    return cleaned_review\n",
    "\n",
    "\n",
    "def review_to_sentences( review: str, tokenizer: nltk.tokenize.punkt.PunktSentenceTokenizer ):\n",
    "\n",
    "    remove_stopwords=False\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "\n",
    "    # try:\n",
    "    #     raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    # except AttributeError:\n",
    "    #     print('weird sentence:')\n",
    "    #     print(review)\n",
    "    #     raw_sentences=[]\n",
    "\n",
    "    review_sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            review_sentences.append( clean_review( raw_sentence,remove_stopwords ))\n",
    "            # L=len(raw_sentence)\n",
    "\n",
    "    \n",
    "    return review_sentences,len(raw_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'........................... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/ ...........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'......'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. .. .. .. .. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.....'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.... .... ... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'... ...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'....'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.......'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..............'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'../ .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'./ .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/ .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'......................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/ ./.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'./.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'...................... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'./...................... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..............................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'...................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. ............. /../ ..... .........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'............................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. .... .. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.......................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. .. .. .. .. .. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. .. .. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/ .. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/ .... .. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'./ ...................... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'............................... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'...............................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'............................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'............'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. ..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.............. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/ ... ... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.........................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'............ .................... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'............................. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.............................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'......................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'WOWOWOWOWOWOWOOWOWOWO ././././.././././.././.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. /.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'...... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'....... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'................................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. ./.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. ../.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'../.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.. .. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.............................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'... ... .. ............. ... ...... ...... .. ... .. ...... ...... ... ...... ........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..........................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'........................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data.recommendation[data.recommendation=='Recommended']=1\n",
    "data.recommendation[data.recommendation=='Not Recommended']=0\n",
    "\n",
    "sentences = []  # Initialize an empty list of sentences\n",
    "sentencesCnt = [] \n",
    "# print(\"Parsing sentences from training set\")\n",
    "cnt=1\n",
    "for review in data['review']:\n",
    "    if pd.isna(review)==False:\n",
    "        Sent,Scnt=review_to_sentences(review, tokenizer)\n",
    "        # sentences += review_to_sentences(review, tokenizer)\n",
    "        sentences+=Sent\n",
    "        sentencesCnt.append(Scnt)\n",
    "    # print(review)\n",
    "    # print('\\n')\n",
    "    cnt+=1\n",
    "    if cnt%50000==0:\n",
    "        print(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.recommendation.describe()\n",
    "# data.head()\n",
    "# sentences[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "from gensim.models import word2vec, KeyedVectors\n",
    "\n",
    "def generate_z1(sentences,num_features,min_word_count,context,num_workers = 4,downsampling = 1e-3, model_name = \"model1_100features_40minwords_5context\"):\n",
    "\n",
    "    print(\"Training model...\")\n",
    "\n",
    "    trained_word2vec_model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling) # \n",
    "    trained_word2vec_model.init_sims(replace=True) # if not plan to train the model any further, much more memory-efficient.\n",
    "    trained_word2vec_model.save(model_name) # load it later using Word2Vec.load()\n",
    "\n",
    "#     z1=trained_word2vec_model.wv.syn0 # not normalized vector\n",
    "    wv=trained_word2vec_model.wv # normalized vector\n",
    "    word_list_z1=trained_word2vec_model.wv.index2word\n",
    "    z1=[]\n",
    "    for i in range(0,len(word_list_z1)):\n",
    "        z1.append(wv[word_list_z1[i]])\n",
    "\n",
    "    z1=np.array(z1,dtype='float32')\n",
    "\n",
    "    return trained_word2vec_model, z1, word_list_z1\n",
    "\n",
    "num_features = 100#300    # Word vector dimensionality                      \n",
    "min_word_count = 40       # Minimum word count                        \n",
    "#     num_workers = 4         # Number of threads to run in parallel\n",
    "context = 5#10            # Context window size                                                                                    \n",
    "#     downsampling = 1e-3       # Downsample setting for frequent words\n",
    "\n",
    "model1, z1, word_list_z1 = generate_z1(sentences,num_features,min_word_count,context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list_z1[0:0]\n",
    "# len(z1)\n",
    "# tokenCnt=[]\n",
    "# VocSize={}\n",
    "# for sent in sentences:\n",
    "#     tokenCnt.append(len(sent))\n",
    "#     for word in sent:\n",
    "#         if word not in VocSize:\n",
    "#             VocSize[word]=1\n",
    "#         else:\n",
    "#             tmp=VocSize[word]\n",
    "#             VocSize[word]=tmp+1\n",
    "\n",
    "\n",
    "import statistics\n",
    "\n",
    "# print(statistics.mean(tokenCnt))##avg token cnt \n",
    "# print(len(VocSize))\n",
    "# print(statistics.mean(sentencesCnt))##avg sentence cnt\n",
    "# sentencesCnt[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "CLUSTER_NUM=80\n",
    "\n",
    "def fit_kmeans(z,word_list_z,num_clusters):\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=1000).fit(z)\n",
    "    Labels=kmeans.labels_\n",
    "    word_centroid_map_z={}\n",
    "    for i in range(0,len(word_list_z)):\n",
    "        word_centroid_map_z[word_list_z[i]]=Labels[i]\n",
    "\n",
    "    return word_centroid_map_z\n",
    "\n",
    "\n",
    "word_centroid_map_z1 = fit_kmeans(z1, word_list_z1, CLUSTER_NUM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The clusters for model1 are....\n",
      "\n",
      "Words of cluster Index 0: \n",
      "['gameplay', 'story', 'experience', 'world', 'mechanics', 'itself', 'pros', 'concept', 'combat', 'sound', 'physics', 'core', 'truly', 'variety', 'aspect', 'design', 'balance', 'sounds', 'music', 'campaign']\n",
      "Words of cluster Index 1: \n",
      "['his', 'kills', 'screaming', 'laugh', 'dies', 'shoots', 'murder', 'scream', 'calling', 'punch', 'stole', 'laughing', 'named', 'finds', 'yelling', 'sees', 'blind', 'calls', 'fired', 'trigger']\n",
      "Words of cluster Index 2: \n",
      "['death', 'action', 'chicken', 'feeling', 'rage', 'heart', 'moments', 'dinner', 'winning', 'adrenaline', 'blood', 'rush', 'pain', 'winner', 'sweet', 'boss', 'frustration', 'edge', 'fear', 'stars']\n",
      "Words of cluster Index 3: \n",
      "['buy', 'recommend', 'm', 'worth', 'am', 'wait', 'im', 'anyone', 'regionlockchina', 'buying', 'highly', 'definitely', 'sale', 'refund', 'recommended', 'reccomend', 'purchase', 'rate', 'nc', 'recomend']\n",
      "Words of cluster Index 4: \n",
      "['life', 'own', 'friend', 'character', 'opinion', 'face', 'hands', 'teammates', 'self', 'body', 'family', 'library', 'eyes', 'bag', 'teammate', 'pants', 'advice', 'position', 'butt', 'brain']\n",
      "Words of cluster Index 5: \n",
      "['de', 'que', 'un', 'es', 'en', 'sa', 'jogo', 'se', 'la', 'si', 'el', 'juego', 'um', 'para', 'q', 'te', 'al', 'le', 'muito', 'bom']\n",
      "Words of cluster Index 6: \n",
      "['sure', 'saying', 'happy', 'sad', 'sorry', 'sick', 'enjoying', 'addicted', 'glad', 'tired', 'interested', 'hoping', 'disappointed', 'excited', 'asking', 'telling', 'loving', 'aware', 'expecting', 'recommending']\n",
      "Words of cluster Index 7: \n",
      "['using', 'killing', 'shooting', 'hunting', 'camping', 'fighting', 'raiding', 'standing', 'destroying', 'chasing', 'forcing', 'spawning', 'stealing', 'beating', 'helping', 'aka', 'remaining', 'teleporting', 'scoring', 'trolling']\n",
      "Words of cluster Index 8: \n",
      "['money', 'free', 'price', 'pay', 'dlc', 'shark', 'cards', 'crates', 'microtransactions', 'cash', 'paid', 'dollars', 'skins', 'pass', 'million', 'key', 'keys', 'micro', 'crate', 'cost']\n",
      "Words of cluster Index 9: \n",
      "['damage', 'fire', 'aim', 'enemy', 'shots', 'bullets', 'cover', 'bullet', 'hits', 'health', 'boost', 'aiming', 'target', 'attacks', 'cam', 'invisible', 'nerf', 'animation', 'npc', 'hooks']\n",
      "Words of cluster Index 10: \n",
      "['etc', 'plus', 'customization', 'available', 'special', 'clothing', 'model', 'selection', 'trading', 'attachments', 'models', 'paint', 'weather', 'upgrades', 'creation', 'hats', 'generated', 'ect', 'optional', 'customisation']\n",
      "Words of cluster Index 11: \n",
      "['servers', 'server', 'bugs', 'lag', 'sometimes', 'loading', 'optimization', 'crashes', 'performance', 'bug', 'connection', 'glitches', 'matchmaking', 'drops', 'lags', 'network', 'desync', 'breaking', 'frame', 'minor']\n",
      "Words of cluster Index 12: \n",
      "['h', 'fortnite', 'z', 'soccer', 'dayz', 'football', 'minecraft', 'br', 'arma', 'skyrim', 'cs', 'csgo', 'san', 'andreas', 'fifa', 'cod', 'ark', 'battlefield', 'strike', 'duty']\n",
      "Words of cluster Index 13: \n",
      "['put', 'goes', 'turn', 'turned', 'fall', 'turns', 'cut', 'pull', 'turning', 'roll', 'holding', 'track', 'fell', 'crack', 'throwing', 'thrown', 'jumped', 'flat', 'knock', 'pulled']\n",
      "Words of cluster Index 14: \n",
      "['they', 'rockstar', 'community', 'product', 'devs', 'modding', 'developers', 'us', 'openiv', 'job', 'bluehole', 'company', 'dev', 'developer', 'capcom', 'themselves', 'interactive', 'attention', 'psyonix', 'clearly']\n",
      "Words of cluster Index 15: \n",
      "['very', 'really', 'too', 'pretty', 'bit', 'overall', 'quite', 'super', 'extremely', 'controls', 'mostly', 'kinda', 'incredibly', 'fairly', 'af', 'paced', 'somewhat', 'beyond', 'slightly', 'generally']\n",
      "Words of cluster Index 16: \n",
      "['control', 'ability', 'range', 'ai', 'movement', 'rng', 'power', 'view', 'difficulty', 'recoil', 'moves', 'ceiling', 'melee', 'bar', 'advanced', 'management', 'raw', 'cap', 'draw', 'handling']\n",
      "Words of cluster Index 17: \n",
      "['china', 'chat', 'name', 'voice', 'word', 'english', 'mic', 'speaking', 'language', 'unknown', 'discord', 'text', 'spam', 'rule', 'names', 'mute', 'numba', 'speaks', 'whom', 'nudity']\n",
      "Words of cluster Index 18: \n",
      "['great', 'nice', 'amazing', 'awesome', 'perfect', 'simple', 'fantastic', 'interesting', 'beautiful', 'solid', 'unique', 'realistic', 'smooth', 'excellent', 'exciting', 'balanced', 'incredible', 'awsome', 'wonderful', 'polished']\n",
      "Words of cluster Index 19: \n",
      "['mouse', 'keyboard', 'menu', 'button', 'camera', 'ui', 'input', 'default', 'menus', 'disable', 'select', 'gender', 'motion', 'workshop', 'function', 'interface', 'ads', 'fov', 'blur', 'buttons']\n",
      "Words of cluster Index 20: \n",
      "['new', 'early', 'update', 'work', 'access', 'content', 'updates', 'release', 'fixed', 'alpha', 'working', 'optimized', 'potential', 'added', 'released', 'future', 'current', 'patch', 'state', 'fixing']\n",
      "Words of cluster Index 21: \n",
      "['since', 'edit', 'finally', 'launch', 'recent', 'recently', 'today', 'th', 'final', 'beginning', 'pre', 'late', 'date', 'hype', 'latest', 'st', 'season', 'following', 'nd', 'weekend']\n",
      "Words of cluster Index 22: \n",
      "['water', 'salt', 'cup', 'butter', 'eggs', 'cheese', 'dough', 'tea', 'heat', 'sugar', 'filling', 'golden', 'combine', 'flour', 'cook', 'ravioli', 'bare', 'mixture', 'lagggslaggg', 'cake']\n",
      "Words of cluster Index 23: \n",
      "['steam', 'screen', 'crash', 'account', 'says', 'error', 'social', 'club', 'code', 'download', 'click', 'failed', 'restart', 'reset', 'mw', 'install', 'message', 'net', 'sign', 'installed']\n",
      "Words of cluster Index 24: \n",
      "['form', 'human', 'dream', 'gamefailed', 'peace', 'relationship', 'class', 'source', 'criminal', 'shape', 'failure', 'pool', 'picture', 'lies', 'owner', 'package', 'rise', 'passion', 'violence', 'glorious']\n",
      "Words of cluster Index 25: \n",
      "['k', 'computer', 'x', 'gb', 'gtx', 'ram', 'internet', 'card', 'windows', 'machine', 'specs', 'minimum', 'cpu', 'laptop', 'ti', 'potato', 'requirements', 'gpu', 'hardware', 'rig']\n",
      "Words of cluster Index 26: \n",
      "['gud', 'kappa', 'ign', 'lit', 'yeet', 'dis', 'dope', 'gaem', 'git', 'gem', 'dank', 'noice', 'meme', 'lul', 'dab', 'gam', 'veri', 'gut', 'boi', 'memes']\n",
      "Words of cluster Index 27: \n",
      "['way', 'reason', 'problem', 'point', 'issue', 'part', 'skill', 'idea', 'chance', 'matter', 'longer', 'luck', 'goal', 'progress', 'option', 'sense', 'sort', 'case', 'curve', 'effort']\n",
      "Words of cluster Index 28: \n",
      "['was', 'played', 'been', 'had', 'got', 'received', 'were', 'come', 'bought', 'started', 'came', 'seen', 'found', 'thought', 'tried', 'went', 'lost', 'gone', 'enjoyed', 'changed']\n",
      "Words of cluster Index 29: \n",
      "['end', 'pick', 'set', 'ed', 'straight', 'step', 'blow', 'shut', 'picking', 'pop', 'ended', 'wake', 'ends', 'screwed', 'picked', 'blown', 'clean', 'blowing', 'messing', 'showing']\n",
      "Words of cluster Index 30: \n",
      "['mod', 'cheating', 'cheat', 'anti', 'hacking', 'hacks', 'hack', 'bans', 'users', 'cheats', 'stream', 'apparently', 'tool', 'legit', 'user', 'software', 'streamer', 'counter', 'aimbot', 'sniping']\n",
      "Words of cluster Index 31: \n",
      "['don', 'doesn', 'isn', 'won', 'didn', 'haven', 'aren', 'wouldn', 'wasn', 'couldn', 'sh', 'shouldn', 'hasn', 'weren', 'ain', 'hadn', 'wan', 'dosen', 'shi', 'havn']\n",
      "Words of cluster Index 32: \n",
      "['games', 'issues', 'things', 'mods', 'problems', 'reviews', 'others', 'cons', 'changes', 'ones', 'flaws', 'reasons', 'improvements', 'words', 'aspects', 'experiences', 'actions', 'complaints', 'rules', 'details']\n",
      "Words of cluster Index 33: \n",
      "['is', 's', 'has', 'makes', 'gets', 'feels', 'thats', 'sucks', 'comes', 'works', 'keeps', 'means', 'gives', 'except', 'gave', 'plays', 'theres', 'happens', 'isnt', 'compared']\n",
      "Words of cluster Index 34: \n",
      "['on', 'from', 'out', 'up', 'by', 'then', 'into', 'over', 'gt', 'back', 'around', 'off', 'down', 'another', 'someone', 'through', 'away', 'next', 'dead', 'him']\n",
      "Words of cluster Index 35: \n",
      "['worst', 'trash', 'stupid', 'hell', 'garbage', 'basically', 'unplayable', 'complete', 'crap', 'piece', 'mess', 'cancer', 'joke', 'shame', 'total', 'pure', 'bs', 'pile', 'essentially', 'microtransaction']\n",
      "Words of cluster Index 36: \n",
      "['region', 'ping', 'official', 'na', 'busy', 'test', 'public', 'asian', 'dedicated', 'eu', 'host', 'american', 'chinaregion', 'north', 'asia', 'sea', 'population', 'country', 'populated', 'south']\n",
      "Words of cluster Index 37: \n",
      "['he', 'naked', 'guy', 'man', 'black', 'hole', 'dude', 'mine', 'her', 'she', 'school', 'trevor', 'star', 'kid', 'white', 'michael', 'dog', 'meat', 'franklin', 'baby']\n",
      "Words of cluster Index 38: \n",
      "['time', 'one', 'hours', 'while', 'two', 'times', 'day', 'minutes', 'years', 'match', 'person', 'year', 'days', 'months', 'place', 'second', 'hour', 'week', 'seconds', 'mission']\n",
      "Words of cluster Index 39: \n",
      "['people', 'players', 'guys', 'kids', 'gamers', 'salty', 'men', 'streamers', 'ppl', 'campers', 'idiots', 'olds', 'noobs', 'children', 'troll', 'russian', 'racist', 'nakeds', 'peoples', 'asians']\n",
      "Words of cluster Index 40: \n",
      "['system', 'base', 'loot', 'items', 'building', 'grind', 'grinding', 'gear', 'resources', 'points', 'crafting', 'item', 'wood', 'space', 'food', 'gathering', 'farming', 'progression', 'tools', 'reward']\n",
      "Words of cluster Index 41: \n",
      "['online', 'single', 'multiplayer', 'mode', 'v', 'solo', 'especially', 'singleplayer', 'both', 'alone', 'pvp', 'competitive', 'offline', 'casual', 'third', 'normal', 'modded', 'co', 'rd', 'private']\n",
      "Words of cluster Index 42: \n",
      "['map', 'house', 'ball', 'head', 'driving', 'wall', 'ground', 'area', 'door', 'circle', 'plane', 'zone', 'line', 'air', 'room', 'field', 'bear', 'jumping', 'hook', 'tree']\n",
      "Words of cluster Index 43: \n",
      "['made', 'done', 'said', 'ruined', 'given', 'called', 'taken', 'removed', 'told', 'created', 'known', 'sold', 'broke', 'developed', 'implemented', 'sent', 'mentioned', 'written', 'disabled', 'introduced']\n",
      "Words of cluster Index 44: \n",
      "['ing', 'f', 'ok', 'lt', 'oh', 'god', 'damn', 'yeah', 'lol', 'wow', 'gg', 'rip', 'xd', 'ur', 'hey', 'wtf', 'pls', 'cuz', 'ya', 'btw']\n",
      "Words of cluster Index 45: \n",
      "['best', 'survival', 'royale', 'favorite', 'type', 'video', 'fan', 'style', 'horror', 'sports', 'true', 'shooter', 'royal', 'similar', 'racing', 'gamer', 'favourite', 'likes', 'greatest', 'sandbox']\n",
      "Words of cluster Index 46: \n",
      "['tho', 'tl', 'dr', 'realy', 'tbh', 'atm', 'soo', 'notmygta', 'indeed', 'iti', 'sooo', 'tldr', 'verry', 'absolutly', 'truely', 'rly', 'summary', 'soooo', 'rep', 'nuff']\n",
      "Words of cluster Index 47: \n",
      "['top', 'side', 'based', 'hand', 'market', 'focus', 'sight', 'plan', 'depending', 'focused', 'depends', 'planet', 'planning', 'behalf', 'basis', 'fence', 'focusing', 'site', 'earth', 'board']\n",
      "Words of cluster Index 48: \n",
      "['store', 'box', 'clothes', 'ceo', 'skin', 'bank', 'pack', 'irl', 'virtual', 'garage', 'fake', 'stock', 'apartment', 'bunker', 'weed', 'office', 'shop', 'cargo', 'mc', 'businesses']\n",
      "Words of cluster Index 49: \n",
      "['toxic', 'friendly', 'popular', 'clear', 'active', 'strong', 'rich', 'powerful', 'creative', 'perhaps', 'involved', 'useful', 'audience', 'helpful', 'skilled', 'cancerous', 'smart', 'successful', 'accurate', 'hostile']\n",
      "Words of cluster Index 50: \n",
      "['with', 'or', 'friends', 'player', 'team', 'killer', 'level', 'random', 'against', 'lobby', 'group', 'survivor', 'together', 'matches', 'squad', 'rank', 'op', 'pro', 'heist', 'party']\n",
      "Words of cluster Index 51: \n",
      "['some', 'most', 'many', 'lot', 'few', 'full', 'these', 'those', 'lots', 'instead', 'alot', 'amount', 'kind', 'couple', 'number', 'tons', 'lack', 'course', 'bunch', 'multiple']\n",
      "Words of cluster Index 52: \n",
      "['can', 'will', 'would', 'want', 'dont', 'need', 'could', 'should', 'd', 'll', 'going', 'cant', 'did', 'does', 'please', 'trying', 'let', 'needs', 'able', 'used']\n",
      "Words of cluster Index 53: \n",
      "['rock', 'gun', 'weapon', 'auto', 'armor', 'shotgun', 'stone', 'pan', 'ak', 'ammo', 'headshot', 'sniper', 'pistol', 'bow', 'rifle', 'lvl', 'double', 'scope', 'torch', 'helmet']\n",
      "Words of cluster Index 54: \n",
      "['car', 'flying', 'crazy', 'balls', 'hot', 'giant', 'bike', 'powered', 'rockets', 'truck', 'tiny', 'motorcycle', 'tank', 'wheels', 'jet', 'bikes', 'explosions', 'strip', 'bomb', 'drink']\n",
      "Words of cluster Index 55: \n",
      "['simulator', 'city', 'race', 'los', 'war', 'desert', 'santos', 'living', 'military', 'zombie', 'movie', 'roam', 'exploring', 'arena', 'mini', 'hockey', 'wild', 'seek', 'miramar', 'chaos']\n",
      "Words of cluster Index 56: \n",
      "['graphics', 'fps', 'high', 'low', 'runs', 'settings', 'looks', 'quality', 'average', 'above', 'speed', 'graphic', 'medium', 'textures', 'max', 'lower', 'mid', 'setting', 'ultra', 'perfectly']\n",
      "Words of cluster Index 57: \n",
      "['more', 'other', 'better', 'less', 'worse', 'rather', 'higher', 'easier', 'faster', 'further', 'harder', 'bigger', 'smaller', 'smoother', 'larger', 'newer', 'slower', 'cheaper', 'stronger', 'significantly']\n",
      "Words of cluster Index 58: \n",
      "['the', 'game', 'and', 'to', 'a', 'i', 'it', 'you', 'this', 'that', 'but', 't', 'not', 'if', 'so', 'my', 'just', 'as', 'all', 'at']\n",
      "Words of cluster Index 59: \n",
      "['fun', 'good', 'well', 'hard', 'little', 'easy', 'cool', 'boring', 'fast', 'enjoyable', 'annoying', 'buggy', 'addictive', 'often', 'laggy', 'frustrating', 'addicting', 'funny', 'slow', 'okay']\n",
      "Words of cluster Index 60: \n",
      "['stuff', 'weapons', 'each', 'missions', 'guns', 'survivors', 'maps', 'killers', 'monsters', 'characters', 'vehicles', 'features', 'heists', 'options', 'ways', 'modes', 'perks', 'skills', 'areas', 'parts']\n",
      "Words of cluster Index 61: \n",
      "['example', 'actual', 'absolute', 'epic', 'entirely', 'attempt', 'empty', 'eye', 'unfinished', 'instant', 'mmo', 'idiot', 'animal', 'opportunity', 'indie', 'addiction', 'exception', 'esport', 'individual', 'essential']\n",
      "Words of cluster Index 62: \n",
      "['care', 'talk', 'thinking', 'talking', 'complain', 'complaining', 'cry', 'worry', 'cares', 'forgot', 'hearing', 'crying', 'worried', 'lying', 'talked', 'whining', 'rant', 'caring', 'cared', 'dunno']\n",
      "Words of cluster Index 63: \n",
      "['make', 'use', 'learn', 'build', 'become', 'master', 'improve', 'choose', 'create', 'sell', 'earn', 'craft', 'destroy', 'practice', 'offer', 'explore', 'gather', 'unlock', 'upgrade', 'possibly']\n",
      "Words of cluster Index 64: \n",
      "['have', 'play', 'be', 'like', 'do', 'love', 'see', 'say', 'know', 'think', 'give', 'enjoy', 'feel', 'hate', 'change', 'mean', 'wish', 'tell', 'understand', 'expect']\n",
      "Words of cluster Index 65: \n",
      "['are', 'fix', 'keep', 'support', 'stop', 'add', 'help', 'ban', 'lock', 'seem', 'bring', 'ruin', 'continue', 'thank', 'avoid', 'show', 'listen', 'allow', 'remove', 'report']\n",
      "Words of cluster Index 66: \n",
      "['for', 'in', 'after', 've', 'every', 'first', 'long', 'almost', 'last', 'spend', 'takes', 'waste', 'whole', 'spent', 'half', 'later', 'ive', 'took', 'short', 'ago']\n",
      "Words of cluster Index 67: \n",
      "['hackers', 'cheaters', 'chinese', 'hacker', 'modders', 'everywhere', 'cheater', 'filled', 'ruining', 'modder', 'rampant', 'trolls', 'toxicity', 'riddled', 'griefers', 'kos', 'plagued', 'dealing', 'infested', 'repeated']\n",
      "Words of cluster Index 68: \n",
      "['their', 'making', 'thanks', 'adding', 'banning', 'greedy', 'keeping', 'creating', 'becoming', 'lazy', 'listening', 'allowing', 'favor', 'removing', 'supporting', 'hungry', 'bringing', 'pushing', 'growing', 'actively']\n",
      "Words of cluster Index 69: \n",
      "['get', 'your', 'take', 'go', 're', 'find', 'run', 'kill', 'start', 'try', 'die', 'open', 'hit', 'look', 'win', 'join', 'load', 'save', 'drop', 'shoot']\n",
      "Words of cluster Index 70: \n",
      "['playing', 'being', 'getting', 'having', 'doing', 'running', 'looking', 'waiting', 'coming', 'taking', 'giving', 'learning', 'starting', 'dying', 'crashing', 'seeing', 'finding', 'looting', 'alive', 'fresh']\n",
      "Words of cluster Index 71: \n",
      "['there', 'bad', 'terrible', 'decent', 'broken', 'poor', 'horrible', 'awful', 'poorly', 'useless', 'important', 'ridiculous', 'insane', 'weird', 'basic', 'dumb', 'clunky', 'common', 'unfair', 'obvious']\n",
      "Words of cluster Index 72: \n",
      "['p', 'r', 'e', 'c', 'o', 'n', 'g', 'b', 'y', 'l', 'w', 'da', 'gr', 'j', 'er', 'ha', 'ma', 'oyun', 'po', 'ist']\n",
      "Words of cluster Index 73: \n",
      "['gta', 'rust', 'pubg', 'battle', 'monster', 'league', 'hunter', 'gaming', 'series', 'grand', 'theft', 'iv', 'title', 'genre', 'previous', 'mh', 'battlegrounds', 'playerunknown', 'masterpiece', 'daylight']\n",
      "Words of cluster Index 74: \n",
      "['review', 'here', 'negative', 'positive', 'read', 'thumbs', 'list', 'write', 'writing', 'reading', 'note', 'rating', 'post', 'personal', 'below', 'mixed', 'comment', 'recommendation', 'award', 'wrote']\n",
      "Words of cluster Index 75: \n",
      "['of', 'same', 'big', 'such', 'different', 'huge', 'due', 'main', 'amp', 'small', 'between', 'large', 'constant', 'despite', 'major', 'massive', 'non', 'certain', 'biggest', 'general']\n",
      "Words of cluster Index 76: \n",
      "['pc', 'version', 'old', 'ps', 'console', 'controller', 'xbox', 'original', 'legacy', 'engine', 'platform', 'consoles', 'mobile', 'older', 'edition', 'cross', 'mac', 'gen', 'versions', 'unreal']\n",
      "Words of cluster Index 77: \n",
      "['com', 'youtube', 'https', 'www', 'videos', 'twitch', 'forums', 'http', 'page', 'reddit', 'google', 'link', 'org', 'tv', 'tutorials', 'info', 'website', 'tips', 'steamcommunity', 'guide']\n",
      "Words of cluster Index 78: \n",
      "['banned', 'killed', 'shot', 'stuck', 'bored', 'raided', 'lucky', 'mad', 'hooked', 'destroyed', 'angry', 'kicked', 'disconnected', 'frustrated', 'caught', 'hacked', 'chased', 'scared', 'rekt', 'geared']\n",
      "Words of cluster Index 79: \n",
      "['cars', 'rocks', 'vehicle', 'walls', 'buildings', 'animals', 'enemies', 'zombies', 'bases', 'houses', 'doors', 'trees', 'bears', 'generators', 'spawns', 'objects', 'planes', 'terrain', 'wolves', 'traps']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "PRINT_NUM=20\n",
    "\n",
    "def print_clusters(word_centroid_map_z, model_name):\n",
    "    \"\"\" Print min(20, cluster_size) words for each of the clusters.\n",
    "\n",
    "        Args: word_centroid_map_z: A mapping of word to cluster index it belongs to. (Dict)  \n",
    "              model_name: Model Name (str)\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"The clusters for {0} are....\\n\".format(model_name))\n",
    "    ### Add your code here.\n",
    "\n",
    "\n",
    "    # pool=[[],[],[],[],[],[],[],[],[],[]]\n",
    "    pool=[]\n",
    "    for i in range(0,CLUSTER_NUM):\n",
    "        pool.append([])\n",
    "\n",
    "\n",
    "\n",
    "    for word in word_centroid_map_z:\n",
    "        index=word_centroid_map_z[word]\n",
    "        if len(pool[index])<PRINT_NUM:\n",
    "            pool[index].append(word)\n",
    "\n",
    "    for i in range(0,CLUSTER_NUM):\n",
    "        print(\"Words of cluster Index {}: \".format(i))\n",
    "        print(pool[i])\n",
    "        # for j in range(0,len(pool[i])):\n",
    "        #     print(pool[i][j])\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ######################\n",
    "\n",
    "print_clusters(word_centroid_map_z1, \"model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster0:  cnt:[144.] sigma:[0.79336663]\n",
      "cluster1:  cnt:[102.] sigma:[0.76284691]\n",
      "cluster2:  cnt:[96.] sigma:[0.79441956]\n",
      "cluster3:  cnt:[99.] sigma:[0.90485482]\n",
      "cluster4:  cnt:[204.] sigma:[0.75063634]\n",
      "cluster5:  cnt:[118.] sigma:[0.41582591]\n",
      "cluster6:  cnt:[111.] sigma:[0.77664874]\n",
      "cluster7:  cnt:[103.] sigma:[0.75952897]\n",
      "cluster8:  cnt:[127.] sigma:[0.82148879]\n",
      "cluster9:  cnt:[190.] sigma:[0.73966598]\n",
      "cluster10:  cnt:[133.] sigma:[0.74459286]\n",
      "cluster11:  cnt:[117.] sigma:[0.78188778]\n",
      "cluster12:  cnt:[97.] sigma:[0.76102043]\n",
      "cluster13:  cnt:[175.] sigma:[0.73815611]\n",
      "cluster14:  cnt:[134.] sigma:[0.80080652]\n",
      "cluster15:  cnt:[83.] sigma:[0.78687405]\n",
      "cluster16:  cnt:[164.] sigma:[0.77935025]\n",
      "cluster17:  cnt:[87.] sigma:[0.80841663]\n",
      "cluster18:  cnt:[173.] sigma:[0.72838705]\n",
      "cluster19:  cnt:[113.] sigma:[0.75089072]\n",
      "cluster20:  cnt:[96.] sigma:[0.86557741]\n",
      "cluster21:  cnt:[92.] sigma:[0.81494276]\n",
      "cluster22:  cnt:[116.] sigma:[0.70088492]\n",
      "cluster23:  cnt:[127.] sigma:[0.77830048]\n",
      "cluster24:  cnt:[208.] sigma:[0.80828757]\n",
      "cluster25:  cnt:[121.] sigma:[0.72140368]\n",
      "cluster26:  cnt:[146.] sigma:[0.72744129]\n",
      "cluster27:  cnt:[146.] sigma:[0.85182481]\n",
      "cluster28:  cnt:[132.] sigma:[0.80846685]\n",
      "cluster29:  cnt:[99.] sigma:[0.67071095]\n",
      "cluster30:  cnt:[130.] sigma:[0.81148329]\n",
      "cluster31:  cnt:[27.] sigma:[0.63574493]\n",
      "cluster32:  cnt:[95.] sigma:[0.81178927]\n",
      "cluster33:  cnt:[141.] sigma:[0.84445961]\n",
      "cluster34:  cnt:[132.] sigma:[0.86872379]\n",
      "cluster35:  cnt:[106.] sigma:[0.82160336]\n",
      "cluster36:  cnt:[81.] sigma:[0.74598547]\n",
      "cluster37:  cnt:[267.] sigma:[0.77394793]\n",
      "cluster38:  cnt:[82.] sigma:[0.83085588]\n",
      "cluster39:  cnt:[124.] sigma:[0.77849093]\n",
      "cluster40:  cnt:[126.] sigma:[0.77014858]\n",
      "cluster41:  cnt:[79.] sigma:[0.83798754]\n",
      "cluster42:  cnt:[231.] sigma:[0.72045209]\n",
      "cluster43:  cnt:[178.] sigma:[0.79904346]\n",
      "cluster44:  cnt:[163.] sigma:[0.82008105]\n",
      "cluster45:  cnt:[112.] sigma:[0.82930345]\n",
      "cluster46:  cnt:[145.] sigma:[0.84915081]\n",
      "cluster47:  cnt:[44.] sigma:[0.76190938]\n",
      "cluster48:  cnt:[77.] sigma:[0.71102295]\n",
      "cluster49:  cnt:[138.] sigma:[0.8044723]\n",
      "cluster50:  cnt:[115.] sigma:[0.83304196]\n",
      "cluster51:  cnt:[69.] sigma:[0.79498643]\n",
      "cluster52:  cnt:[87.] sigma:[0.83902129]\n",
      "cluster53:  cnt:[124.] sigma:[0.67855974]\n",
      "cluster54:  cnt:[163.] sigma:[0.71790736]\n",
      "cluster55:  cnt:[147.] sigma:[0.7748275]\n",
      "cluster56:  cnt:[102.] sigma:[0.79330217]\n",
      "cluster57:  cnt:[52.] sigma:[0.74614181]\n",
      "cluster58:  cnt:[160.] sigma:[0.94448564]\n",
      "cluster59:  cnt:[112.] sigma:[0.75763726]\n",
      "cluster60:  cnt:[131.] sigma:[0.74231038]\n",
      "cluster61:  cnt:[128.] sigma:[0.74555917]\n",
      "cluster62:  cnt:[41.] sigma:[0.69216422]\n",
      "cluster63:  cnt:[123.] sigma:[0.79376841]\n",
      "cluster64:  cnt:[98.] sigma:[0.81606369]\n",
      "cluster65:  cnt:[110.] sigma:[0.82229619]\n",
      "cluster66:  cnt:[82.] sigma:[0.86451134]\n",
      "cluster67:  cnt:[65.] sigma:[0.75513989]\n",
      "cluster68:  cnt:[121.] sigma:[0.8117408]\n",
      "cluster69:  cnt:[141.] sigma:[0.81566938]\n",
      "cluster70:  cnt:[101.] sigma:[0.83572156]\n",
      "cluster71:  cnt:[138.] sigma:[0.76718796]\n",
      "cluster72:  cnt:[166.] sigma:[0.6044229]\n",
      "cluster73:  cnt:[109.] sigma:[0.83677973]\n",
      "cluster74:  cnt:[80.] sigma:[0.83522045]\n",
      "cluster75:  cnt:[167.] sigma:[0.85839134]\n",
      "cluster76:  cnt:[76.] sigma:[0.80031602]\n",
      "cluster77:  cnt:[75.] sigma:[0.72334136]\n",
      "cluster78:  cnt:[107.] sigma:[0.70051255]\n",
      "cluster79:  cnt:[129.] sigma:[0.70749459]\n",
      "[0.77728356]\n"
     ]
    }
   ],
   "source": [
    "cluster_centroid=np.zeros((CLUSTER_NUM,100))\n",
    "cluster_cnt=np.zeros((CLUSTER_NUM,1))\n",
    "cluster_sigma=np.zeros((CLUSTER_NUM,1))\n",
    "\n",
    "L=len(z1)\n",
    "for i in range(0,L):\n",
    "     cluster=word_centroid_map_z1[word_list_z1[i]]\n",
    "     cluster_centroid[cluster]+=z1[i]\n",
    "     cluster_cnt[cluster]+=1\n",
    "\n",
    "for i in range(0,CLUSTER_NUM):\n",
    "     cluster_centroid[i]=cluster_centroid[i]/cluster_cnt[i]\n",
    "\n",
    "for i in range(0,L):\n",
    "     cluster=word_centroid_map_z1[word_list_z1[i]]\n",
    "     cluster_sigma[cluster]+=sum(np.square(z1[i]-cluster_centroid[cluster]))\n",
    "\n",
    "Sum=0\n",
    "for i in range(0,CLUSTER_NUM):\n",
    "     cluster_sigma[i]=np.sqrt(cluster_sigma[i]/cluster_cnt[i])\n",
    "     Sum+=cluster_sigma[i]\n",
    "     print(\"cluster\"+str(i)+\":  cnt:\"+str(cluster_cnt[i])+\" sigma:\"+str(cluster_sigma[i]))\n",
    "\n",
    "print(Sum/CLUSTER_NUM)\n",
    "\n",
    "\n",
    "# print(statistics.mean(cluster_sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Product received for free. Note I got the free auto install since I had all of the DLC for the originalI don't really see the point except that Bethesda has realized that a year after Fallout IV (fairly typical timeframe for a new announcement or game release for Elder Scrolls) there is nothing going on. They want to try to build hype and make everyone dream of a new Elder Scrolls game.Well I'm still dreaming. This game looks much the same as the PC version I had before. I had a few mods (water updates fire textures yeah those bright glowing logs and some add ons) but nothing that greatly changed the visuals. They could at least have added some new content a quest series a new guild ride around in wagons ANYTHING. Now I have to go find new mods for everything (inventory window skills/leveling).I'm quite disappointed in the release. Maybe I'll go back and play ME2 &amp ME 3 at least they have a new game releasing soon . . .\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster_centroid[0]\n",
    "# IDX=0\n",
    "# cluster=word_centroid_map_z1[word_list_z1[IDX]]\n",
    "# print(sum(np.square(z1[IDX])))\n",
    "# print(cluster)\n",
    "# print(z1[IDX])\n",
    "# print(z1[IDX]-cluster_centroid[cluster])\n",
    "# print(sum(np.square(z1[IDX]-cluster_centroid[cluster])))\n",
    "# data[0:5]\n",
    "data.review[433376]\n",
    "# 434891\n",
    "# 433375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.....'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'... ...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'....'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.......'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..............'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'......................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..............................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'. . . .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'...................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.......................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'............................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'............'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.........................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'/.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'......'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.............................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'......................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'SERVERS ARE TOO BUSY EVERYDAY!!!!!!!!!!!!!!!!!. WOWOWOWOWOWOWOOWOWOWO ././././.././././.././.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'................................................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'. . .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'..........................................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'........................'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\python37\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'. '\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Cleaned\n"
     ]
    }
   ],
   "source": [
    "clean_train_reviews = []\n",
    "\n",
    "def preprocess_review(review):\n",
    "\n",
    "    review_text = BeautifulSoup(review,\"lxml\").get_text()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "#     clean_review=\" \".join(meaningful_words) ## marked to avoid being split again\n",
    "    \n",
    "    return meaningful_words #clean_review\n",
    "\n",
    "cnt=1\n",
    "for review in data['review']:\n",
    "    clean_train_reviews.append(preprocess_review(review))\n",
    "    if cnt%50000==0:\n",
    "        print(cnt)\n",
    "    cnt+=1\n",
    "\n",
    "print(\"Train Cleaned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def create_bag_of_centroids(tokenized_review, word_centroid_map, num_clusters,normalize):\n",
    "\n",
    "    bag_of_centroids=[]\n",
    "    for i in range(0,num_clusters):\n",
    "        bag_of_centroids.append(0)\n",
    "\n",
    "    for i in range(0,len(tokenized_review)):\n",
    "        if tokenized_review[i] in word_centroid_map:\n",
    "            bag_of_centroids[word_centroid_map[tokenized_review[i]]]=bag_of_centroids[word_centroid_map[tokenized_review[i]]]+1\n",
    "\n",
    "    if normalize==0:\n",
    "        return bag_of_centroids\n",
    "    else:\n",
    "        Sum=sum(bag_of_centroids)\n",
    "        if Sum!=0:\n",
    "            bag_of_centroids=[x / Sum for x in bag_of_centroids]\n",
    "        return bag_of_centroids\n",
    "\n",
    "\n",
    "def create_design_matrices(cleaned_reviews, word_centroid_map_z1, num_clusters,normalize):\n",
    "\n",
    "    X1=[]\n",
    "    for i in range(0,len(cleaned_reviews)):\n",
    "          X1.append(create_bag_of_centroids(cleaned_reviews[i], word_centroid_map_z1, num_clusters ,normalize))\n",
    "\n",
    "    x1_data=np.array(X1)\n",
    "\n",
    "    return x1_data\n",
    "\n",
    "NORMALIZE=1\n",
    "X_Train = create_design_matrices(clean_train_reviews,word_centroid_map_z1,CLUSTER_NUM, NORMALIZE)\n",
    "Y_Train = data.recommendation.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.05882353 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05882353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.\n",
      "  0.         0.         0.         0.         0.29411765 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05882353 0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.\n",
      "  0.         0.05882353 0.         0.         0.05882353 0.\n",
      "  0.         0.         0.         0.         0.         0.05882353\n",
      "  0.         0.         0.         0.23529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.0625     0.\n",
      "  0.         0.         0.0625     0.         0.         0.\n",
      "  0.         0.         0.         0.0625     0.0625     0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.0625     0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25       0.125\n",
      "  0.         0.         0.         0.         0.0625     0.\n",
      "  0.         0.         0.         0.         0.0625     0.\n",
      "  0.         0.         0.         0.         0.0625     0.\n",
      "  0.         0.        ]\n",
      " [0.         0.0104712  0.         0.0052356  0.0052356  0.\n",
      "  0.         0.0052356  0.         0.         0.         0.\n",
      "  0.         0.         0.02094241 0.02094241 0.         0.02094241\n",
      "  0.0104712  0.         0.         0.0052356  0.         0.0052356\n",
      "  0.0052356  0.         0.         0.         0.0052356  0.01570681\n",
      "  0.         0.         0.0104712  0.02094241 0.02094241 0.01570681\n",
      "  0.         0.01570681 0.06282723 0.04188482 0.0052356  0.01570681\n",
      "  0.0052356  0.         0.03664921 0.01570681 0.         0.\n",
      "  0.         0.0052356  0.07329843 0.         0.03664921 0.\n",
      "  0.         0.         0.         0.         0.12041885 0.02094241\n",
      "  0.         0.         0.03664921 0.0104712  0.10994764 0.0104712\n",
      "  0.02094241 0.         0.         0.05235602 0.02094241 0.\n",
      "  0.         0.         0.04712042 0.0052356  0.0052356  0.0052356\n",
      "  0.01570681 0.        ]\n",
      " [0.0078125  0.0234375  0.0078125  0.0234375  0.0234375  0.\n",
      "  0.         0.0078125  0.         0.0234375  0.         0.\n",
      "  0.         0.0078125  0.0234375  0.015625   0.         0.0078125\n",
      "  0.         0.         0.         0.         0.0078125  0.\n",
      "  0.         0.         0.015625   0.0234375  0.         0.\n",
      "  0.0078125  0.         0.0078125  0.0078125  0.046875   0.\n",
      "  0.         0.         0.03125    0.03125    0.0078125  0.0078125\n",
      "  0.         0.015625   0.0234375  0.         0.         0.\n",
      "  0.         0.         0.0546875  0.0078125  0.03125    0.\n",
      "  0.0078125  0.         0.         0.0078125  0.1484375  0.0703125\n",
      "  0.0234375  0.         0.         0.0078125  0.0546875  0.0390625\n",
      "  0.0078125  0.0078125  0.         0.078125   0.         0.015625\n",
      "  0.         0.0078125  0.0078125  0.0078125  0.0078125  0.\n",
      "  0.         0.        ]]\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_Train[0:5])\n",
    "print(Y_Train[0:5])\n",
    "# np.save('Train_r470k_knn80_n1_1.npy', X_Train)\n",
    "# np.save('Label_r470k_1.npy', Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # f=open('/Users/shyang/Desktop/GT/2020Spring/6240/project/steam_reviews.json','r')\n",
    "# f=open('steam_reviews.json','r')\n",
    "\n",
    "# # wanted_columns=['username','hours','products','product_id','page_order','date','text','early_access','page','found_funny','compensation','user_id']\n",
    "# wanted_columns=['hours','products','product_id','page_order','date','text','early_access','page','found_funny','compensation']\n",
    "\n",
    "# dict_wanted_columns={}\n",
    "# for keys in wanted_columns:\n",
    "#     dict_wanted_columns[keys]='1'\n",
    "# dropped_column={}\n",
    "\n",
    "# integer_columns={'page_order':'1','page':'1','found_funny':'1','products':1}\n",
    "# float_columns={'hours':'1'}\n",
    "# cat_columns={'product_id','early_access','compensation'}\n",
    "# # TF_columns={'early_access':'1','compensation':'1'}\n",
    "# ### the rest is string, so far: text, \n",
    "# game_id_dict={}\n",
    "\n",
    "# data=pd.DataFrame(columns=wanted_columns)\n",
    "# cnt=1\n",
    "# for line in f.readlines():\n",
    "\n",
    "#     # line=line.strip('{u\\'')\n",
    "#     line=line[3:(len(line)-2)]\n",
    "#     # line=line.strip('}')\n",
    "#     line=line.split(', u\\'')\n",
    "#     d={}\n",
    "#     for seg in line:\n",
    "\n",
    "#         try:\n",
    "\n",
    "#             # print(seg)\n",
    "#             seg=seg.split('\\': ')\n",
    "#             # print(seg)\n",
    "\n",
    "#             if seg[0] not in dict_wanted_columns:\n",
    "#                 if seg[0] not in dropped_column:\n",
    "#                     dropped_column[seg[0]]='1'\n",
    "#                 continue\n",
    "\n",
    "#             if seg[0]=='text' and len(seg)==3:## bugfix1\n",
    "#                 seg[1]=seg[2]\n",
    "\n",
    "#             if seg[1][0]=='u' and seg[1][1]=='\\'' and seg[1][len(seg[1])-1]=='\\'':\n",
    "#                 seg[1]=seg[1][2:len(seg[1])-1] \n",
    "#             # print(seg)\n",
    "\n",
    "#             ### assign specific data format\n",
    "#             if seg[0] in integer_columns:\n",
    "#                 seg[1]=int(seg[1])\n",
    "#             # if seg[0] == 'early_access':\n",
    "#             #     seg[1]=int(seg[1])\n",
    "#             # if seg[0] == 'compensation':\n",
    "#             #     seg[1]='True'\n",
    "#             if seg[0] in float_columns:\n",
    "#                 seg[1]=float(seg[1])\n",
    "#             if seg[0] =='text':\n",
    "#                 if seg[1][0:2]=='u\\\"':\n",
    "#                     seg[1]=seg[1][2:len(seg[1])]\n",
    "\n",
    "#                 letters_only = re.sub(\"[^a-zA-Z]\", \" \", seg[1])\n",
    "#                 # words = letters_only.lower().split()\n",
    "#                 # stops = set(stopwords.words(\"english\"))\n",
    "#                 # meaningful_words = [w for w in words if not w in stops]\n",
    "#                 # seg[1]=\" \".join(meaningful_words)\n",
    "#                 seg[1]=\" \".join(letters_only.lower().split())\n",
    "\n",
    "#             if seg[0] == 'product_id': ## build game_id histogram\n",
    "#                 if seg[1] in game_id_dict:\n",
    "#                     game_id_dict[seg[1]]=game_id_dict[seg[1]]+1\n",
    "#                 else:\n",
    "#                     game_id_dict[seg[1]]=1\n",
    "\n",
    "#             d[seg[0]]=[seg[1]]\n",
    "\n",
    "#         except IndexError:\n",
    "#             print(cnt)\n",
    "#             print(seg)\n",
    "#             print(len(seg))\n",
    "#             print(len(seg[0]))\n",
    "#             print(len(seg[1]))\n",
    "\n",
    "\n",
    "#     # print(d)\n",
    "\n",
    "#     ### fill NAN term\n",
    "#     if 'compensation' not in d:\n",
    "#         d['compensation']=['False']\n",
    "#     if 'found_funny' not in d:\n",
    "#         d['found_funny']=[0]\n",
    "\n",
    "#     df=pd.DataFrame(data=d)\n",
    "#     data=pd.concat([data, df],axis=0,ignore_index=True,sorted=False)\n",
    "\n",
    "#     cnt=cnt+1\n",
    "#     if cnt%10000==0:\n",
    "#         print(cnt)\n",
    "#     # if cnt==20:\n",
    "#     #     break\n",
    "\n",
    "\n",
    "# # print(data[0:20])\n",
    "# print(data.shape)\n",
    "# print(dropped_column)\n",
    "# print(game_id_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(d)\n",
    "# test=pd.DataFrame(data=d)\n",
    "# test.head()\n",
    "# data.found_funny.describe()\n",
    "# data.compensation.describe()\n",
    "# data.early_access.describe()\n",
    "# print(dict_wanted_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from google.colab import files\n",
    "\n",
    "# json = json.dumps(game_id_dict)\n",
    "# f = open(\"game_id_dict.json\",\"w\")\n",
    "# f.write(json)\n",
    "# f.close()\n",
    "# # files.download(\"game_id_dict.json\") \n",
    "# data.to_pickle('processed_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# # print(os.path.abspath(\"steam_reviews.json\"))\n",
    "# print(os.getcwd())\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import json\n",
    "# # from google.colab import files\n",
    "\n",
    "# # json = json.dumps(data)\n",
    "# # f = open(\"processed_data.json\",\"w\")\n",
    "# # f.write(json)\n",
    "# # f.close()\n",
    "# # files.download(\"processed_data.json\") \n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# a=pd.read_pickle('processed_data.pkl')\n",
    "# # print(a)\n",
    "# with open('game_id_dict.json', 'r') as f:\n",
    "#     b = json.load(f)\n",
    "# # print(b)\n",
    "\n",
    "# f=open('/Users/shyang/Desktop/GT/2020Spring/6240/project/dim_Game','r')\n",
    "# Nicole_dict={}\n",
    "# # cnt=1\n",
    "# for line in f.readlines():\n",
    "#     line=line.split(',')\n",
    "#     if line[2]=='\\n':\n",
    "#         # value='NA'\n",
    "#         continue\n",
    "#     else:\n",
    "#         value=line[2].strip('\\n')\n",
    "\n",
    "#     # if line[1] in Nicole_dict:\n",
    "#     #     print(line[1])\n",
    "\n",
    "#     Nicole_dict[line[1]]=value\n",
    "\n",
    "#     # cnt=cnt+1\n",
    "#     # if cnt==5:\n",
    "#     #     break\n",
    "\n",
    "# # print(Nicole_dict)\n",
    "# correct=0\n",
    "# wrong=0\n",
    "# for key in b:\n",
    "#     if key in Nicole_dict:\n",
    "#         word=Nicole_dict[key][0]\n",
    "#         # print(word,re.fullmatch(\"[0-9]\",word))\n",
    "#         if re.fullmatch(\"[0-9]\",word) != None:\n",
    "#             cnt=int(word)\n",
    "#             if cnt==b[key]:\n",
    "#                 correct=correct+1\n",
    "#             else:\n",
    "#                 wrong=wrong+1\n",
    "\n",
    "#         # print(b[key],Nicole_dict[key])\n",
    "# print(correct,wrong)\n",
    "\n",
    "# toWhale={}\n",
    "# for key in b:\n",
    "#     if b[key]>=10:\n",
    "#         toWhale[key]=b[key]\n",
    "\n",
    "# import json\n",
    "# json = json.dumps(toWhale)\n",
    "# f = open(\"valid_game_id.json\",\"w\")\n",
    "# f.write(json)\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=open('/Users/shyang/Desktop/GT/2020Spring/6240/project/steam_reviews.json','r')\n",
    "# data=[]\n",
    "# cnt=1\n",
    "# for line in f.readlines():\n",
    "\n",
    "#     line=line.strip('{')\n",
    "#     line=line.strip('}')\n",
    "#     line=line.split(', u\\'')\n",
    "#     # for seg in line:\n",
    "#     #     seg=seg.strip()    \n",
    "#     print(line)\n",
    "#     cnt=cnt+1\n",
    "#     if cnt==5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "w2a7XWZw2Eio",
    "outputId": "a1cb46ac-5974-4a83-80fa-961e06db3029"
   },
   "outputs": [],
   "source": [
    "# ### To ensure required data exist.\n",
    "# import os\n",
    "# print(os.getcwd())\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Machine Learning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from random import sample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training data model selection\n",
    "def mycv(model,x_train,y_train, cv=5):\n",
    "    score_dic = cross_validate(model, x_train,y_train, cv=5, scoring=['f1', 'recall', 'precision', 'accuracy'])\n",
    "    f1 = np.mean(score_dic['test_f1'])\n",
    "    recall = np.mean(score_dic['test_recall'])\n",
    "    precision = np.mean(score_dic['test_precision'])\n",
    "    acc = np.mean(score_dic['test_accuracy'])\n",
    "    print(\"%.4f\" % f1,\"%.4f\" %  recall, \"%.4f\" % precision, \"%.4f\" % acc)\n",
    "    return f1, recall, precision, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for test\n",
    "def metric(y_true, y_pred):\n",
    "  acc = accuracy_score(y_true, y_pred)\n",
    "  precision = precision_score(y_true, y_pred)\n",
    "  recall = recall_score(y_true, y_pred)\n",
    "  f1 =  f1_score(y_true, y_pred)\n",
    "  print(\"%.4f\" % f1,\"%.4f\" %  recall, \"%.4f\" % precision, \"%.4f\" % acc)\n",
    "  return f1, recall, precision, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Train_df = pd.DataFrame(Y_Train, columns=['sentiment'], dtype=np.int8)\n",
    "X_Train_df = pd.DataFrame(X_Train,  dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## balance data\n",
    "dropid = Y_Train_df[Y_Train_df['sentiment'] == 1].sample(frac = 0.568543126, random_state = 0)\n",
    "X_Train_balance = X_Train_df.drop(dropid.index)\n",
    "Y_Train_balance = Y_Train_df.drop(dropid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, label):\n",
    "    \"\"\"Helper function to create a train-test split of the data.(test_size = 0.2, random_state = 0)\n",
    "\n",
    "     Arg: X: Design Matrix(ndarray)\n",
    "          label: sentiment values\n",
    "     Returns:\n",
    "          x_train: train input features\n",
    "          x_test: test input features\n",
    "          y_train: train labels\n",
    "          y_test: test labels\n",
    "    \"\"\"\n",
    "    ###Add your code here.\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, label, test_size=0.2, random_state=0)\n",
    "    #####################\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = split(X_Train_balance, Y_Train_balance.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261248, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Train_balance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning\n",
    "def cross_val(x_train_split,y_train_split,n_estimators):\n",
    "    \"\"\"function to calculate the cross validation scores for the values of x_train, and y_train on the Classifier.\n",
    "\n",
    "     Arg: x_train_split: train input features\n",
    "          y_train_split: train labels\n",
    "          n_estimators: List of estimators to perform Random Forest with.\n",
    "     Returns:\n",
    "          cross_val_scores: List of the CV scores the estimators (list)\n",
    "    \"\"\"\n",
    "    \n",
    "    ###Add your code here.\n",
    "    cross_val_scores = []\n",
    "    \n",
    "#     f1_list = []\n",
    "    for i in n_estimators: \n",
    "        print(\"------Now calculating  \" +str(i))\n",
    "        forest = RandomForestClassifier(n_estimators = i, max_depth = 10, random_state = 0)\n",
    "        forest = forest.fit(x_train_split, y_train_split)            \n",
    "        score_list = cross_val_score(forest, x_train_split,y_train_split, cv=5)\n",
    "        score = sum(score_list)/len(score_list)\n",
    "        print(i, score)\n",
    "        cross_val_scores.append(score)\n",
    "    \n",
    "    #####################\n",
    "    return cross_val_scores\n",
    "\n",
    "# n_estimators = [50, 100, 500, 750]\n",
    "# result1 = cross_val(x_train, y_train,n_estimators) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The optimal number of trees is 750\n",
    "forest = RandomForestClassifier(n_estimators = 750, random_state = 0)\n",
    "forest = forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature importance\n",
    "# forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-da8124e114b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmycv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-87-4ac5c1027d4a>\u001b[0m in \u001b[0;36mmycv\u001b[1;34m(model, x_train, y_train, cv)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# for training data model selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmycv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mscore_dic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_f1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_recall'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 232\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_generate_sample_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'subsample'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mycv(forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7830813397129187 0.7755400540054005 0.7944905486399262 0.7849009337280801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7830813397129187,\n",
       " 0.7755400540054005,\n",
       " 0.7944905486399262,\n",
       " 0.7849009337280801)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_rf = forest.predict(x_test)\n",
    "# metric(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(cv = 5, random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7631 0.7577 0.7685 0.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7631029256831947, 0.7577441030170364, 0.7685458875806997, 0.764552785428717)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycv(lr, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.42215497e-01,  2.10245790e+00,  5.42759326e+00,\n",
       "         8.26361401e-02,  2.73739449e+00,  7.60890644e-01,\n",
       "         1.17362281e+00, -1.10586127e+00, -2.63409877e+00,\n",
       "        -8.03375417e-01,  2.69936134e-01, -4.12619796e+00,\n",
       "         1.29976122e-01, -5.66816359e-01, -4.61672477e+00,\n",
       "         2.40094388e+00, -1.16766039e+00,  3.73029178e-01,\n",
       "         1.15461070e+01, -2.45947943e+00, -1.61656877e+00,\n",
       "        -1.09606152e+00,  1.38838292e+00, -3.63763952e+00,\n",
       "        -7.67133547e-02, -7.79652510e-01,  2.55731417e+00,\n",
       "        -3.67121324e+00,  2.67532977e+00, -1.90864156e+00,\n",
       "        -8.87162911e+00, -3.04382339e+00, -3.18558484e+00,\n",
       "        -2.16262413e+00, -1.71681649e+00, -9.09955227e+00,\n",
       "        -3.07254096e+00,  1.78886303e+00, -9.08399601e-01,\n",
       "        -9.05345955e-01, -1.10285822e+00, -1.03294184e+00,\n",
       "         3.23183204e-01, -3.54149638e+00,  5.89601331e-04,\n",
       "         1.01620943e+01,  1.09643074e+00, -8.05180623e-02,\n",
       "        -5.63025360e-01,  2.50672531e-01,  1.32663544e+00,\n",
       "        -4.55747896e-02, -1.17755009e+00,  1.32256010e+00,\n",
       "         3.99166117e+00,  1.52635237e+00, -1.15358006e+00,\n",
       "         2.18129051e-01,  1.16173909e-01,  3.49173585e+00,\n",
       "         2.39335750e+00,  7.47154006e-01, -3.10403231e-01,\n",
       "        -4.83020858e-01,  1.51948917e+00, -3.22109392e+00,\n",
       "        -2.78232190e+00, -6.75316039e+00, -7.41182025e+00,\n",
       "        -1.32530157e+00,  1.68372702e-01, -4.19141660e+00,\n",
       "         2.86716854e-02,  3.27093838e-01,  8.55674662e-01,\n",
       "        -6.70852738e-01, -1.78819885e-01, -5.11119657e-01,\n",
       "        -2.58359845e+00,  3.89274086e+00]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## feature importance\n",
    "# lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_lr = lr.predict(x_test)\n",
    "# metric(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsvm = svm.SVC(kernel='linear').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_svm = gsvm.predict(x_test)\n",
    "# metric(y_test, y_pred_svm)\n",
    "\n",
    "## In this problem, SVM is computational expensive, so we give up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Naive Bayes classifier for multinomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7415 0.7018 0.7861 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7415450046227636,\n",
       " 0.7017955229663502,\n",
       " 0.7860892198764745,\n",
       " 0.7551842800101232)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycv(nb, x_train, y_train)\n",
    "# y_pred_nb = nb.predict(x_test)\n",
    "# metric(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7308 0.7535 0.7094 0.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.730793835899223, 0.7535087193734699, 0.7094236760061615, 0.7221743731701953)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycv(tree, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
